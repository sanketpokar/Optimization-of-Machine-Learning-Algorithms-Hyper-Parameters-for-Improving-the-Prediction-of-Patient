{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebe3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f5852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e55fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>SARS-Cov-2 exam result</th>\n",
       "      <th>Patient addmited to regular ward (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to semi-intensive unit (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to intensive care unit (1=yes, 0=no)</th>\n",
       "      <th>Hematocrit</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Mean platelet volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Hb saturation (arterial blood gases)</th>\n",
       "      <th>pCO2 (arterial blood gas analysis)</th>\n",
       "      <th>Base excess (arterial blood gas analysis)</th>\n",
       "      <th>pH (arterial blood gas analysis)</th>\n",
       "      <th>Total CO2 (arterial blood gas analysis)</th>\n",
       "      <th>HCO3 (arterial blood gas analysis)</th>\n",
       "      <th>pO2 (arterial blood gas analysis)</th>\n",
       "      <th>Arteiral Fio2</th>\n",
       "      <th>Phosphor</th>\n",
       "      <th>ctO2 (arterial blood gas analysis)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44477f75e8169d2</td>\n",
       "      <td>13</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126e9dd13932f68</td>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236515</td>\n",
       "      <td>-0.022340</td>\n",
       "      <td>-0.517413</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a46b4402a0e5696</td>\n",
       "      <td>8</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f7d619a94f97c45</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9e41465789c2b5</td>\n",
       "      <td>15</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>ae66feb9e4dc3a0</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>517c2834024f3ea</td>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>5c57d6037fe266d</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5642</th>\n",
       "      <td>c20c44766f28291</td>\n",
       "      <td>10</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>2697fdccbfeb7f7</td>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.694287</td>\n",
       "      <td>0.541564</td>\n",
       "      <td>-0.906829</td>\n",
       "      <td>-0.325903</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5644 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Patient ID  Patient age quantile SARS-Cov-2 exam result  \\\n",
       "0     44477f75e8169d2                    13               negative   \n",
       "1     126e9dd13932f68                    17               negative   \n",
       "2     a46b4402a0e5696                     8               negative   \n",
       "3     f7d619a94f97c45                     5               negative   \n",
       "4     d9e41465789c2b5                    15               negative   \n",
       "...               ...                   ...                    ...   \n",
       "5639  ae66feb9e4dc3a0                     3               positive   \n",
       "5640  517c2834024f3ea                    17               negative   \n",
       "5641  5c57d6037fe266d                     4               negative   \n",
       "5642  c20c44766f28291                    10               negative   \n",
       "5643  2697fdccbfeb7f7                    19               positive   \n",
       "\n",
       "      Patient addmited to regular ward (1=yes, 0=no)  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "5639                                               0   \n",
       "5640                                               0   \n",
       "5641                                               0   \n",
       "5642                                               0   \n",
       "5643                                               0   \n",
       "\n",
       "      Patient addmited to semi-intensive unit (1=yes, 0=no)  \\\n",
       "0                                                     0       \n",
       "1                                                     0       \n",
       "2                                                     0       \n",
       "3                                                     0       \n",
       "4                                                     0       \n",
       "...                                                 ...       \n",
       "5639                                                  0       \n",
       "5640                                                  0       \n",
       "5641                                                  0       \n",
       "5642                                                  0       \n",
       "5643                                                  0       \n",
       "\n",
       "      Patient addmited to intensive care unit (1=yes, 0=no)  Hematocrit  \\\n",
       "0                                                     0             NaN   \n",
       "1                                                     0        0.236515   \n",
       "2                                                     0             NaN   \n",
       "3                                                     0             NaN   \n",
       "4                                                     0             NaN   \n",
       "...                                                 ...             ...   \n",
       "5639                                                  0             NaN   \n",
       "5640                                                  0             NaN   \n",
       "5641                                                  0             NaN   \n",
       "5642                                                  0             NaN   \n",
       "5643                                                  0        0.694287   \n",
       "\n",
       "      Hemoglobin  Platelets  Mean platelet volume   ...  \\\n",
       "0            NaN        NaN                    NaN  ...   \n",
       "1      -0.022340  -0.517413               0.010677  ...   \n",
       "2            NaN        NaN                    NaN  ...   \n",
       "3            NaN        NaN                    NaN  ...   \n",
       "4            NaN        NaN                    NaN  ...   \n",
       "...          ...        ...                    ...  ...   \n",
       "5639         NaN        NaN                    NaN  ...   \n",
       "5640         NaN        NaN                    NaN  ...   \n",
       "5641         NaN        NaN                    NaN  ...   \n",
       "5642         NaN        NaN                    NaN  ...   \n",
       "5643    0.541564  -0.906829              -0.325903  ...   \n",
       "\n",
       "      Hb saturation (arterial blood gases)  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "...                                    ...   \n",
       "5639                                   NaN   \n",
       "5640                                   NaN   \n",
       "5641                                   NaN   \n",
       "5642                                   NaN   \n",
       "5643                                   NaN   \n",
       "\n",
       "      pCO2 (arterial blood gas analysis)  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "...                                  ...   \n",
       "5639                                 NaN   \n",
       "5640                                 NaN   \n",
       "5641                                 NaN   \n",
       "5642                                 NaN   \n",
       "5643                                 NaN   \n",
       "\n",
       "      Base excess (arterial blood gas analysis)  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "...                                         ...   \n",
       "5639                                        NaN   \n",
       "5640                                        NaN   \n",
       "5641                                        NaN   \n",
       "5642                                        NaN   \n",
       "5643                                        NaN   \n",
       "\n",
       "      pH (arterial blood gas analysis)  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "4                                  NaN   \n",
       "...                                ...   \n",
       "5639                               NaN   \n",
       "5640                               NaN   \n",
       "5641                               NaN   \n",
       "5642                               NaN   \n",
       "5643                               NaN   \n",
       "\n",
       "      Total CO2 (arterial blood gas analysis)  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "5639                                      NaN   \n",
       "5640                                      NaN   \n",
       "5641                                      NaN   \n",
       "5642                                      NaN   \n",
       "5643                                      NaN   \n",
       "\n",
       "      HCO3 (arterial blood gas analysis)  pO2 (arterial blood gas analysis)  \\\n",
       "0                                    NaN                                NaN   \n",
       "1                                    NaN                                NaN   \n",
       "2                                    NaN                                NaN   \n",
       "3                                    NaN                                NaN   \n",
       "4                                    NaN                                NaN   \n",
       "...                                  ...                                ...   \n",
       "5639                                 NaN                                NaN   \n",
       "5640                                 NaN                                NaN   \n",
       "5641                                 NaN                                NaN   \n",
       "5642                                 NaN                                NaN   \n",
       "5643                                 NaN                                NaN   \n",
       "\n",
       "      Arteiral Fio2  Phosphor  ctO2 (arterial blood gas analysis)  \n",
       "0               NaN       NaN                                 NaN  \n",
       "1               NaN       NaN                                 NaN  \n",
       "2               NaN       NaN                                 NaN  \n",
       "3               NaN       NaN                                 NaN  \n",
       "4               NaN       NaN                                 NaN  \n",
       "...             ...       ...                                 ...  \n",
       "5639            NaN       NaN                                 NaN  \n",
       "5640            NaN       NaN                                 NaN  \n",
       "5641            NaN       NaN                                 NaN  \n",
       "5642            NaN       NaN                                 NaN  \n",
       "5643            NaN       NaN                                 NaN  \n",
       "\n",
       "[5644 rows x 111 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd3c1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "eightypercent = 5644*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5d64a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data:\n",
    "    if data[column].isna().sum()>(5644*0.8):\n",
    "        del data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bb0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f04e8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(['not_detected'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b0448bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>SARS-Cov-2 exam result</th>\n",
       "      <th>Patient addmited to regular ward (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to semi-intensive unit (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to intensive care unit (1=yes, 0=no)</th>\n",
       "      <th>Respiratory Syncytial Virus</th>\n",
       "      <th>Influenza A</th>\n",
       "      <th>Influenza B</th>\n",
       "      <th>Parainfluenza 1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parainfluenza 3</th>\n",
       "      <th>Chlamydophila pneumoniae</th>\n",
       "      <th>Adenovirus</th>\n",
       "      <th>Parainfluenza 4</th>\n",
       "      <th>Coronavirus229E</th>\n",
       "      <th>CoronavirusOC43</th>\n",
       "      <th>Inf A H1N1 2009</th>\n",
       "      <th>Bordetella pertussis</th>\n",
       "      <th>Metapneumovirus</th>\n",
       "      <th>Parainfluenza 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126e9dd13932f68</td>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9e41465789c2b5</td>\n",
       "      <td>15</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8bb9d64f0215244</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5f1ed301375586c</td>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0fbafd910aa8078</td>\n",
       "      <td>13</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>c5b44ff9c7782fd</td>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>dd9c139e93b5894</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>88cce1444e16f9c</td>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>2733fac0d3f7138</td>\n",
       "      <td>15</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>acd761fe16b5d0f</td>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1352 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Patient ID  Patient age quantile SARS-Cov-2 exam result  \\\n",
       "1     126e9dd13932f68                    17               negative   \n",
       "4     d9e41465789c2b5                    15               negative   \n",
       "8     8bb9d64f0215244                     1               negative   \n",
       "9     5f1ed301375586c                    17               negative   \n",
       "13    0fbafd910aa8078                    13               negative   \n",
       "...               ...                   ...                    ...   \n",
       "5602  c5b44ff9c7782fd                    19               negative   \n",
       "5607  dd9c139e93b5894                     0               negative   \n",
       "5614  88cce1444e16f9c                    19               negative   \n",
       "5615  2733fac0d3f7138                    15               negative   \n",
       "5618  acd761fe16b5d0f                    17               negative   \n",
       "\n",
       "      Patient addmited to regular ward (1=yes, 0=no)  \\\n",
       "1                                                  0   \n",
       "4                                                  0   \n",
       "8                                                  0   \n",
       "9                                                  0   \n",
       "13                                                 0   \n",
       "...                                              ...   \n",
       "5602                                               0   \n",
       "5607                                               0   \n",
       "5614                                               0   \n",
       "5615                                               0   \n",
       "5618                                               0   \n",
       "\n",
       "      Patient addmited to semi-intensive unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     1       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Patient addmited to intensive care unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     0       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Respiratory Syncytial Virus  Influenza A  Influenza B  Parainfluenza 1  \\\n",
       "1                               0            0            0                0   \n",
       "4                               0            0            0                0   \n",
       "8                               0            0            0                0   \n",
       "9                               0            0            0                0   \n",
       "13                              0            0            0                0   \n",
       "...                           ...          ...          ...              ...   \n",
       "5602                            0            0            0                0   \n",
       "5607                            1            0            0                0   \n",
       "5614                            0            0            0                0   \n",
       "5615                            0            0            0                0   \n",
       "5618                            0            0            0                0   \n",
       "\n",
       "      ...  Parainfluenza 3  Chlamydophila pneumoniae  Adenovirus  \\\n",
       "1     ...                0                         0           0   \n",
       "4     ...                0                         0           0   \n",
       "8     ...                0                         0           0   \n",
       "9     ...                0                         0           0   \n",
       "13    ...                0                         0           0   \n",
       "...   ...              ...                       ...         ...   \n",
       "5602  ...                0                         0           0   \n",
       "5607  ...                0                         0           0   \n",
       "5614  ...                0                         0           0   \n",
       "5615  ...                0                         0           0   \n",
       "5618  ...                0                         0           0   \n",
       "\n",
       "      Parainfluenza 4  Coronavirus229E  CoronavirusOC43  Inf A H1N1 2009  \\\n",
       "1                   0                0                0                0   \n",
       "4                   0                0                0                0   \n",
       "8                   0                0                0                0   \n",
       "9                   0                0                0                0   \n",
       "13                  0                0                0                0   \n",
       "...               ...              ...              ...              ...   \n",
       "5602                0                0                0                0   \n",
       "5607                0                0                0                0   \n",
       "5614                0                0                0                0   \n",
       "5615                0                0                0                0   \n",
       "5618                0                0                0                0   \n",
       "\n",
       "      Bordetella pertussis  Metapneumovirus  Parainfluenza 2  \n",
       "1                        0                0                0  \n",
       "4                        0                0                0  \n",
       "8                        0                0                0  \n",
       "9                        0                0                0  \n",
       "13                       0                0                0  \n",
       "...                    ...              ...              ...  \n",
       "5602                     0                0                0  \n",
       "5607                     0                0                0  \n",
       "5614                     0                0                0  \n",
       "5615                     0                0                0  \n",
       "5618                     0                0                0  \n",
       "\n",
       "[1352 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace(['detected'], 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66de38d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>SARS-Cov-2 exam result</th>\n",
       "      <th>Patient addmited to regular ward (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to semi-intensive unit (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to intensive care unit (1=yes, 0=no)</th>\n",
       "      <th>Respiratory Syncytial Virus</th>\n",
       "      <th>Influenza A</th>\n",
       "      <th>Influenza B</th>\n",
       "      <th>Parainfluenza 1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parainfluenza 3</th>\n",
       "      <th>Chlamydophila pneumoniae</th>\n",
       "      <th>Adenovirus</th>\n",
       "      <th>Parainfluenza 4</th>\n",
       "      <th>Coronavirus229E</th>\n",
       "      <th>CoronavirusOC43</th>\n",
       "      <th>Inf A H1N1 2009</th>\n",
       "      <th>Bordetella pertussis</th>\n",
       "      <th>Metapneumovirus</th>\n",
       "      <th>Parainfluenza 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126e9dd13932f68</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9e41465789c2b5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8bb9d64f0215244</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5f1ed301375586c</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0fbafd910aa8078</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>c5b44ff9c7782fd</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>dd9c139e93b5894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>88cce1444e16f9c</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>2733fac0d3f7138</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>acd761fe16b5d0f</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1352 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Patient ID  Patient age quantile  SARS-Cov-2 exam result  \\\n",
       "1     126e9dd13932f68                    17                       0   \n",
       "4     d9e41465789c2b5                    15                       0   \n",
       "8     8bb9d64f0215244                     1                       0   \n",
       "9     5f1ed301375586c                    17                       0   \n",
       "13    0fbafd910aa8078                    13                       0   \n",
       "...               ...                   ...                     ...   \n",
       "5602  c5b44ff9c7782fd                    19                       0   \n",
       "5607  dd9c139e93b5894                     0                       0   \n",
       "5614  88cce1444e16f9c                    19                       0   \n",
       "5615  2733fac0d3f7138                    15                       0   \n",
       "5618  acd761fe16b5d0f                    17                       0   \n",
       "\n",
       "      Patient addmited to regular ward (1=yes, 0=no)  \\\n",
       "1                                                  0   \n",
       "4                                                  0   \n",
       "8                                                  0   \n",
       "9                                                  0   \n",
       "13                                                 0   \n",
       "...                                              ...   \n",
       "5602                                               0   \n",
       "5607                                               0   \n",
       "5614                                               0   \n",
       "5615                                               0   \n",
       "5618                                               0   \n",
       "\n",
       "      Patient addmited to semi-intensive unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     1       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Patient addmited to intensive care unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     0       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Respiratory Syncytial Virus  Influenza A  Influenza B  Parainfluenza 1  \\\n",
       "1                               0            0            0                0   \n",
       "4                               0            0            0                0   \n",
       "8                               0            0            0                0   \n",
       "9                               0            0            0                0   \n",
       "13                              0            0            0                0   \n",
       "...                           ...          ...          ...              ...   \n",
       "5602                            0            0            0                0   \n",
       "5607                            1            0            0                0   \n",
       "5614                            0            0            0                0   \n",
       "5615                            0            0            0                0   \n",
       "5618                            0            0            0                0   \n",
       "\n",
       "      ...  Parainfluenza 3  Chlamydophila pneumoniae  Adenovirus  \\\n",
       "1     ...                0                         0           0   \n",
       "4     ...                0                         0           0   \n",
       "8     ...                0                         0           0   \n",
       "9     ...                0                         0           0   \n",
       "13    ...                0                         0           0   \n",
       "...   ...              ...                       ...         ...   \n",
       "5602  ...                0                         0           0   \n",
       "5607  ...                0                         0           0   \n",
       "5614  ...                0                         0           0   \n",
       "5615  ...                0                         0           0   \n",
       "5618  ...                0                         0           0   \n",
       "\n",
       "      Parainfluenza 4  Coronavirus229E  CoronavirusOC43  Inf A H1N1 2009  \\\n",
       "1                   0                0                0                0   \n",
       "4                   0                0                0                0   \n",
       "8                   0                0                0                0   \n",
       "9                   0                0                0                0   \n",
       "13                  0                0                0                0   \n",
       "...               ...              ...              ...              ...   \n",
       "5602                0                0                0                0   \n",
       "5607                0                0                0                0   \n",
       "5614                0                0                0                0   \n",
       "5615                0                0                0                0   \n",
       "5618                0                0                0                0   \n",
       "\n",
       "      Bordetella pertussis  Metapneumovirus  Parainfluenza 2  \n",
       "1                        0                0                0  \n",
       "4                        0                0                0  \n",
       "8                        0                0                0  \n",
       "9                        0                0                0  \n",
       "13                       0                0                0  \n",
       "...                    ...              ...              ...  \n",
       "5602                     0                0                0  \n",
       "5607                     0                0                0  \n",
       "5614                     0                0                0  \n",
       "5615                     0                0                0  \n",
       "5618                     0                0                0  \n",
       "\n",
       "[1352 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace(['negative'], 0)\n",
    "data = data.replace(['positive'], 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a57758",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Patient ID']\n",
    "del data['Parainfluenza 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c0e1c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>SARS-Cov-2 exam result</th>\n",
       "      <th>Patient addmited to regular ward (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to semi-intensive unit (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to intensive care unit (1=yes, 0=no)</th>\n",
       "      <th>Respiratory Syncytial Virus</th>\n",
       "      <th>Influenza A</th>\n",
       "      <th>Influenza B</th>\n",
       "      <th>Parainfluenza 1</th>\n",
       "      <th>CoronavirusNL63</th>\n",
       "      <th>...</th>\n",
       "      <th>Coronavirus HKU1</th>\n",
       "      <th>Parainfluenza 3</th>\n",
       "      <th>Chlamydophila pneumoniae</th>\n",
       "      <th>Adenovirus</th>\n",
       "      <th>Parainfluenza 4</th>\n",
       "      <th>Coronavirus229E</th>\n",
       "      <th>CoronavirusOC43</th>\n",
       "      <th>Inf A H1N1 2009</th>\n",
       "      <th>Bordetella pertussis</th>\n",
       "      <th>Metapneumovirus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1352 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient age quantile  SARS-Cov-2 exam result  \\\n",
       "1                       17                       0   \n",
       "4                       15                       0   \n",
       "8                        1                       0   \n",
       "9                       17                       0   \n",
       "13                      13                       0   \n",
       "...                    ...                     ...   \n",
       "5602                    19                       0   \n",
       "5607                     0                       0   \n",
       "5614                    19                       0   \n",
       "5615                    15                       0   \n",
       "5618                    17                       0   \n",
       "\n",
       "      Patient addmited to regular ward (1=yes, 0=no)  \\\n",
       "1                                                  0   \n",
       "4                                                  0   \n",
       "8                                                  0   \n",
       "9                                                  0   \n",
       "13                                                 0   \n",
       "...                                              ...   \n",
       "5602                                               0   \n",
       "5607                                               0   \n",
       "5614                                               0   \n",
       "5615                                               0   \n",
       "5618                                               0   \n",
       "\n",
       "      Patient addmited to semi-intensive unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     1       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Patient addmited to intensive care unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     0       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Respiratory Syncytial Virus  Influenza A  Influenza B  Parainfluenza 1  \\\n",
       "1                               0            0            0                0   \n",
       "4                               0            0            0                0   \n",
       "8                               0            0            0                0   \n",
       "9                               0            0            0                0   \n",
       "13                              0            0            0                0   \n",
       "...                           ...          ...          ...              ...   \n",
       "5602                            0            0            0                0   \n",
       "5607                            1            0            0                0   \n",
       "5614                            0            0            0                0   \n",
       "5615                            0            0            0                0   \n",
       "5618                            0            0            0                0   \n",
       "\n",
       "      CoronavirusNL63  ...  Coronavirus HKU1  Parainfluenza 3  \\\n",
       "1                   0  ...                 0                0   \n",
       "4                   0  ...                 0                0   \n",
       "8                   0  ...                 0                0   \n",
       "9                   0  ...                 0                0   \n",
       "13                  0  ...                 0                0   \n",
       "...               ...  ...               ...              ...   \n",
       "5602                0  ...                 0                0   \n",
       "5607                0  ...                 0                0   \n",
       "5614                0  ...                 0                0   \n",
       "5615                0  ...                 0                0   \n",
       "5618                0  ...                 0                0   \n",
       "\n",
       "      Chlamydophila pneumoniae  Adenovirus  Parainfluenza 4  Coronavirus229E  \\\n",
       "1                            0           0                0                0   \n",
       "4                            0           0                0                0   \n",
       "8                            0           0                0                0   \n",
       "9                            0           0                0                0   \n",
       "13                           0           0                0                0   \n",
       "...                        ...         ...              ...              ...   \n",
       "5602                         0           0                0                0   \n",
       "5607                         0           0                0                0   \n",
       "5614                         0           0                0                0   \n",
       "5615                         0           0                0                0   \n",
       "5618                         0           0                0                0   \n",
       "\n",
       "      CoronavirusOC43  Inf A H1N1 2009  Bordetella pertussis  Metapneumovirus  \n",
       "1                   0                0                     0                0  \n",
       "4                   0                0                     0                0  \n",
       "8                   0                0                     0                0  \n",
       "9                   0                0                     0                0  \n",
       "13                  0                0                     0                0  \n",
       "...               ...              ...                   ...              ...  \n",
       "5602                0                0                     0                0  \n",
       "5607                0                0                     0                0  \n",
       "5614                0                0                     0                0  \n",
       "5615                0                0                     0                0  \n",
       "5618                0                0                     0                0  \n",
       "\n",
       "[1352 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb29697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"SARS-Cov-2 exam result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de4e31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.copy()\n",
    "del x[\"SARS-Cov-2 exam result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f1284bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>Patient addmited to regular ward (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to semi-intensive unit (1=yes, 0=no)</th>\n",
       "      <th>Patient addmited to intensive care unit (1=yes, 0=no)</th>\n",
       "      <th>Respiratory Syncytial Virus</th>\n",
       "      <th>Influenza A</th>\n",
       "      <th>Influenza B</th>\n",
       "      <th>Parainfluenza 1</th>\n",
       "      <th>CoronavirusNL63</th>\n",
       "      <th>Rhinovirus/Enterovirus</th>\n",
       "      <th>Coronavirus HKU1</th>\n",
       "      <th>Parainfluenza 3</th>\n",
       "      <th>Chlamydophila pneumoniae</th>\n",
       "      <th>Adenovirus</th>\n",
       "      <th>Parainfluenza 4</th>\n",
       "      <th>Coronavirus229E</th>\n",
       "      <th>CoronavirusOC43</th>\n",
       "      <th>Inf A H1N1 2009</th>\n",
       "      <th>Bordetella pertussis</th>\n",
       "      <th>Metapneumovirus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1352 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient age quantile  Patient addmited to regular ward (1=yes, 0=no)  \\\n",
       "1                       17                                               0   \n",
       "4                       15                                               0   \n",
       "8                        1                                               0   \n",
       "9                       17                                               0   \n",
       "13                      13                                               0   \n",
       "...                    ...                                             ...   \n",
       "5602                    19                                               0   \n",
       "5607                     0                                               0   \n",
       "5614                    19                                               0   \n",
       "5615                    15                                               0   \n",
       "5618                    17                                               0   \n",
       "\n",
       "      Patient addmited to semi-intensive unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     1       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Patient addmited to intensive care unit (1=yes, 0=no)  \\\n",
       "1                                                     0       \n",
       "4                                                     0       \n",
       "8                                                     0       \n",
       "9                                                     0       \n",
       "13                                                    0       \n",
       "...                                                 ...       \n",
       "5602                                                  0       \n",
       "5607                                                  0       \n",
       "5614                                                  0       \n",
       "5615                                                  0       \n",
       "5618                                                  0       \n",
       "\n",
       "      Respiratory Syncytial Virus  Influenza A  Influenza B  Parainfluenza 1  \\\n",
       "1                               0            0            0                0   \n",
       "4                               0            0            0                0   \n",
       "8                               0            0            0                0   \n",
       "9                               0            0            0                0   \n",
       "13                              0            0            0                0   \n",
       "...                           ...          ...          ...              ...   \n",
       "5602                            0            0            0                0   \n",
       "5607                            1            0            0                0   \n",
       "5614                            0            0            0                0   \n",
       "5615                            0            0            0                0   \n",
       "5618                            0            0            0                0   \n",
       "\n",
       "      CoronavirusNL63  Rhinovirus/Enterovirus  Coronavirus HKU1  \\\n",
       "1                   0                       1                 0   \n",
       "4                   0                       1                 0   \n",
       "8                   0                       0                 0   \n",
       "9                   0                       0                 0   \n",
       "13                  0                       0                 0   \n",
       "...               ...                     ...               ...   \n",
       "5602                0                       0                 0   \n",
       "5607                0                       0                 0   \n",
       "5614                0                       0                 0   \n",
       "5615                0                       0                 0   \n",
       "5618                0                       0                 0   \n",
       "\n",
       "      Parainfluenza 3  Chlamydophila pneumoniae  Adenovirus  Parainfluenza 4  \\\n",
       "1                   0                         0           0                0   \n",
       "4                   0                         0           0                0   \n",
       "8                   0                         0           0                0   \n",
       "9                   0                         0           0                0   \n",
       "13                  0                         0           0                0   \n",
       "...               ...                       ...         ...              ...   \n",
       "5602                0                         0           0                0   \n",
       "5607                0                         0           0                0   \n",
       "5614                0                         0           0                0   \n",
       "5615                0                         0           0                0   \n",
       "5618                0                         0           0                0   \n",
       "\n",
       "      Coronavirus229E  CoronavirusOC43  Inf A H1N1 2009  Bordetella pertussis  \\\n",
       "1                   0                0                0                     0   \n",
       "4                   0                0                0                     0   \n",
       "8                   0                0                0                     0   \n",
       "9                   0                0                0                     0   \n",
       "13                  0                0                0                     0   \n",
       "...               ...              ...              ...                   ...   \n",
       "5602                0                0                0                     0   \n",
       "5607                0                0                0                     0   \n",
       "5614                0                0                0                     0   \n",
       "5615                0                0                0                     0   \n",
       "5618                0                0                0                     0   \n",
       "\n",
       "      Metapneumovirus  \n",
       "1                   0  \n",
       "4                   0  \n",
       "8                   0  \n",
       "9                   0  \n",
       "13                  0  \n",
       "...               ...  \n",
       "5602                0  \n",
       "5607                0  \n",
       "5614                0  \n",
       "5615                0  \n",
       "5618                0  \n",
       "\n",
       "[1352 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93fde2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9595a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array = x_train.to_numpy()\n",
    "y_train_array = y_train.to_numpy()\n",
    "x_test_array = x_test.to_numpy()\n",
    "y_test_array = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49ac96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM starts\n",
    "machine = svm.SVC()\n",
    "machine.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a4bfb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVM = machine.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d49f0433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.915129151291513\n",
      "Precision:  0.915129151291513\n",
      "Recall:  0.0\n",
      "F1Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_pred_SVM))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_pred_SVM))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_pred_SVM))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb71703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [100, 10, 1], \n",
    "    'cache_size': [10, 20],\n",
    "    'gamma': [0.00001, 0.0001, 0.001, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c39a5ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(machine, param_grid, scoring='f1', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "406de640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.154 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.286 total time=   0.2s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.250 total time=   0.2s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.083 total time=   0.3s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.323 total time=   0.4s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.4s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.154 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.296 total time=  16.4s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.190 total time=  10.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.087 total time=  12.5s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.385 total time=  10.9s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.571 total time=  23.3s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.296 total time=  17.5s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.190 total time=  18.8s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.087 total time=  19.7s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.429 total time=  21.3s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.533 total time=  21.5s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.154 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.286 total time=  22.7s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.240 total time=  20.7s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.087 total time=   9.9s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.167 total time=  30.5s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.190 total time=  27.4s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.235 total time= 2.6min\n",
      "[CV 2/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.200 total time= 1.9min\n",
      "[CV 3/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.083 total time= 1.9min\n",
      "[CV 4/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.067 total time= 2.0min\n",
      "[CV 5/5] END C=100, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.486 total time= 2.6min\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.154 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.286 total time=   0.2s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.250 total time=   0.2s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.083 total time=   0.3s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.323 total time=   0.4s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.4s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.154 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.296 total time=  16.4s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.190 total time=   9.9s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.087 total time=  12.5s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.385 total time=  10.8s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.571 total time=  23.3s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.296 total time=  17.5s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.190 total time=  18.8s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.087 total time=  19.7s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.429 total time=  21.3s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.533 total time=  21.5s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.154 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.286 total time=  22.7s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.240 total time=  20.7s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.087 total time=   9.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.167 total time=  30.3s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.190 total time=  27.6s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.235 total time= 2.6min\n",
      "[CV 2/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.200 total time= 1.9min\n",
      "[CV 3/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.083 total time= 1.9min\n",
      "[CV 4/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.067 total time= 2.0min\n",
      "[CV 5/5] END C=100, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.486 total time= 2.6min\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.296 total time=   0.8s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.190 total time=   0.5s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.087 total time=   0.6s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.414 total time=   1.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.621 total time=   0.4s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.296 total time=   2.7s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.190 total time=   3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.087 total time=   2.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.429 total time=   2.4s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.533 total time=   2.2s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.286 total time=  11.9s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.273 total time=   9.3s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.087 total time=   5.3s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.414 total time=  16.5s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.621 total time=  17.8s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.286 total time= 2.0min\n",
      "[CV 2/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.250 total time=  59.2s\n",
      "[CV 3/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.083 total time= 1.6min\n",
      "[CV 4/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.091 total time= 1.5min\n",
      "[CV 5/5] END C=10, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.600 total time= 1.6min\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.296 total time=   0.8s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.190 total time=   0.5s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.087 total time=   0.6s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.414 total time=   1.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.621 total time=   0.4s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.296 total time=   2.7s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.190 total time=   3.1s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.087 total time=   2.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.429 total time=   2.4s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.533 total time=   2.2s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.296 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.286 total time=  11.9s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.273 total time=   9.4s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.087 total time=   5.3s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.414 total time=  16.6s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.621 total time=  17.9s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.087 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.273 total time=   0.0s\n",
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.286 total time=   0.0s\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.083 total time=   0.0s\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.323 total time=   0.0s\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.286 total time= 2.0min\n",
      "[CV 2/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.250 total time=  59.8s\n",
      "[CV 3/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.083 total time= 1.6min\n",
      "[CV 4/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.091 total time= 1.5min\n",
      "[CV 5/5] END C=10, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.600 total time= 1.6min\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.348 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=rbf;, score=0.190 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.296 total time=   0.6s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.190 total time=   0.3s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.087 total time=   0.5s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.357 total time=   1.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=0.1, kernel=poly;, score=0.621 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.348 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=rbf;, score=0.190 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.296 total time=   0.3s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.190 total time=   0.2s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.087 total time=   0.2s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.385 total time=   0.3s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=2, gamma=1, kernel=poly;, score=0.571 total time=   0.2s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.296 total time=   6.1s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.100 total time=   6.4s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.091 total time=   4.2s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.385 total time=   8.8s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=0.1, kernel=poly;, score=0.571 total time=   7.8s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.348 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=rbf;, score=0.190 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.286 total time= 2.0min\n",
      "[CV 2/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.250 total time= 1.2min\n",
      "[CV 3/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.087 total time=  54.9s\n",
      "[CV 4/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.320 total time= 1.7min\n",
      "[CV 5/5] END C=1, cache_size=10, degree=3, gamma=1, kernel=poly;, score=0.562 total time= 1.4min\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=0.1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.348 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=rbf;, score=0.190 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=1, gamma=1, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.296 total time=   0.6s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.190 total time=   0.3s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.087 total time=   0.5s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.357 total time=   1.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=0.1, kernel=poly;, score=0.621 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.348 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=rbf;, score=0.190 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.296 total time=   0.3s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.190 total time=   0.2s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.087 total time=   0.2s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.385 total time=   0.3s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=2, gamma=1, kernel=poly;, score=0.571 total time=   0.2s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=1e-05, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.0001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.001, kernel=poly;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.296 total time=   6.1s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.100 total time=   6.4s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.091 total time=   4.5s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.385 total time=   8.4s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=0.1, kernel=poly;, score=0.571 total time=   7.8s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.348 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=rbf;, score=0.190 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.080 total time=   0.0s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=linear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.286 total time= 2.0min\n",
      "[CV 2/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.250 total time= 1.2min\n",
      "[CV 3/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.087 total time=  54.8s\n",
      "[CV 4/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.320 total time= 1.7min\n",
      "[CV 5/5] END C=1, cache_size=20, degree=3, gamma=1, kernel=poly;, score=0.562 total time= 1.4min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [100, 10, 1], 'cache_size': [10, 20],\n",
       "                         'degree': [1, 2, 3],\n",
       "                         'gamma': [1e-05, 0.0001, 0.001, 0.1, 1],\n",
       "                         'kernel': ['rbf', 'linear', 'poly']},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "680f1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'cache_size': 10, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "280d9f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_opti = svm.SVC(kernel='poly', C=10, cache_size=10, degree=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "433f9fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=10, gamma=0.1, kernel='poly')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_opti.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8903a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_opti_pred_SVM = machine_opti.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57567dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9372693726937269\n",
      "Precision:  0.9372693726937269\n",
      "Recall:  0.25\n",
      "F1Score:  0.37037037037037035\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_opti_pred_SVM))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_opti_pred_SVM))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_opti_pred_SVM))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_opti_pred_SVM))\n",
    "\n",
    "\n",
    "#SVM ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df57d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Starts\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc2a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = classifier.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0ca3ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.922509225092251\n",
      "Precision:  0.922509225092251\n",
      "Recall:  0.2608695652173913\n",
      "F1Score:  0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_pred_DT))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_pred_DT))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_pred_DT))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d513c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_DT = {\n",
    "    'min_samples_leaf':[1,2,3], \n",
    "    'min_samples_split':[2,3,4,5], \n",
    "    'splitter':['random', 'best'],\n",
    "    'random_state':[0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d1d5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchDT = GridSearchCV(classifier, param_grid_DT, scoring = 'f1', verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34a81363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=random;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=random;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=best;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=2, random_state=0, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=random;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=random;, score=0.296 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=random;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=best;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=2, random_state=1, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=random;, score=0.348 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=random;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=random;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=3, random_state=0, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=random;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=random;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=random;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=best;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=3, random_state=1, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=random;, score=0.308 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=random;, score=0.417 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=random;, score=0.231 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=random;, score=0.538 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=best;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=best;, score=0.231 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=4, random_state=0, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=random;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=random;, score=0.222 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=random;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=random;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=best;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=best;, score=0.231 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=4, random_state=1, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=random;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=random;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=random;, score=0.480 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=best;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=5, random_state=0, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=random;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=random;, score=0.480 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=best;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=best;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=best;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, min_samples_split=5, random_state=1, splitter=best;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=2, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=2, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=3, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=3, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=4, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=4, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=random;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=random;, score=0.091 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=5, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=best;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=2, min_samples_split=5, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=random;, score=0.345 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=random;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=random;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=2, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=2, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=random;, score=0.345 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=random;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=random;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=3, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=3, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=random;, score=0.345 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=random;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=random;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=4, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=4, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=random;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=random;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=random;, score=0.345 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=random;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=random;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=5, random_state=0, splitter=best;, score=0.261 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=random;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=random;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=random;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=random;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=best;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=best;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=best;, score=0.091 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=best;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, min_samples_split=5, random_state=1, splitter=best;, score=0.261 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3, 4, 5],\n",
       "                         'random_state': [0, 1],\n",
       "                         'splitter': ['random', 'best']},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchDT.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10c00a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 1, 'min_samples_split': 4, 'random_state': 0, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "print(searchDT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "720ffec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTclassifier_opti = DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split=5, random_state=0, splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32d8db84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(min_samples_split=5, random_state=0, splitter='random')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTclassifier_opti.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0687d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_opti_pred_DT = DTclassifier_opti.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "965db9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9298892988929889\n",
      "Precision:  0.9298892988929889\n",
      "Recall:  0.2608695652173913\n",
      "F1Score:  0.3870967741935483\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_opti_pred_DT))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_opti_pred_DT))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_opti_pred_DT))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_opti_pred_DT))\n",
    "\n",
    "#DT ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e5705ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Forestclassifier = RandomForestClassifier()\n",
    "Forestclassifier.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c815d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = Forestclassifier.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54eda90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.922509225092251\n",
      "Precision:  0.922509225092251\n",
      "Recall:  0.30434782608695654\n",
      "F1Score:  0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_pred_RF))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_pred_RF))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_pred_RF))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1550fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_RF = {'bootstrap': [True, False],\n",
    "                'ccp_alpha' : [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                'criterion' : ['gini', 'entropy'],\n",
    "                'max_depth' : [None, 10, 15, 20, 25],\n",
    "                'min_samples_leaf' : [1,2,3],\n",
    "                'n_estimators' : [25,50,75,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2143ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchFC = GridSearchCV(Forestclassifier, param_grid_RF, scoring='f1', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "912d3844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.100 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.095 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.273 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.364 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.095 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.095 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.480 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.400 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.381 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.105 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.261 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.400 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.308 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.417 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.455 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.200 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.095 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.095 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.364 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.522 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.174 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.417 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.087 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.261 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.308 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.400 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.308 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.273 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=True, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.381 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.095 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.308 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.455 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.522 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.240 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.105 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.095 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.200 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.261 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.308 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.174 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.273 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.167 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.167 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.348 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.167 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.320 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.348 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.174 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.105 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.182 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.273 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.190 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.100 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.0, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.1, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.2, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.3, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.4, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=gini, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=15, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=20, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=75;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=1, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=50;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=2, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=25;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=50;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=75;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, ccp_alpha=0.5, criterion=entropy, max_depth=25, min_samples_leaf=3, n_estimators=100;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 10, 15, 20, 25],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'n_estimators': [25, 50, 75, 100]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchFC.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "74a91b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "print(searchFC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bf57846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ForestClassifier_opti = RandomForestClassifier(bootstrap= True, ccp_alpha = 0.0, criterion = 'gini', max_depth = 15, min_samples_leaf = 1, n_estimators = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1b6d32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ForestClassifier_opti.fit(x_train_array, y_train_array)\n",
    "y_opti_pred_FC = ForestClassifier_opti.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4c83c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9261992619926199\n",
      "Precision:  0.9261992619926199\n",
      "Recall:  0.30434782608695654\n",
      "F1Score:  0.411764705882353\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_opti_pred_FC))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_opti_pred_FC))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_opti_pred_FC))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_opti_pred_FC))\n",
    "\n",
    "\n",
    "#Forest Classifier ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1e154cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adaboost classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adbclassifier = AdaBoostClassifier()\n",
    "adbclassifier.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b56cc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ADB = adbclassifier.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f30f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.922509225092251\n",
      "Precision:  0.922509225092251\n",
      "Recall:  0.21739130434782608\n",
      "F1Score:  0.3225806451612903\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_pred_ADB))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_pred_ADB))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_pred_ADB))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_pred_ADB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5b4ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'base_estimator', 'learning_rate', 'n_estimators', 'random_state'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adbclassifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b03fcf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ADB = {\n",
    "    'algorithm' : ['SAMME', 'SAMME.R'],\n",
    "    'learning_rate' : [1.0, 0.1, 0.3, 0.5, 0.75, 1.25, 1.5],\n",
    "    'n_estimators' : [25, 50, 75, 100, 125],\n",
    "    'random_state' : [0,1,None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af41364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchADB = GridSearchCV(adbclassifier, param_grid_ADB, scoring='f1', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ddbf330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 210 candidates, totalling 1050 fits\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.105 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.095 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.095 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.095 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.240 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.095 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.095 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.095 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.190 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.240 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.182 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=25, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=50, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=75, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=0;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.273 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=1;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=100, random_state=None;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=0;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=1;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.0, n_estimators=125, random_state=None;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=50, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=75, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.105 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.231 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.231 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.231 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=100, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.231 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=0;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.231 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.231 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=125, random_state=None;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=0;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=1;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.095 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=25, random_state=None;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.200 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.200 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.200 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=50, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.222 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=75, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=0;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=1;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=100, random_state=None;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=0;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=1;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.3, n_estimators=125, random_state=None;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.105 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=25, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=50, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.222 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=75, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=0;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=1;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=100, random_state=None;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=0;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=1;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.222 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=125, random_state=None;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.231 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=25, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=50, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.222 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=75, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=0;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=1;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=100, random_state=None;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=0;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=1;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.261 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.154 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.75, n_estimators=125, random_state=None;, score=0.111 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=0;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=1;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.320 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=25, random_state=None;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=50, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.160 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.160 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.273 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.160 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=75, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=0;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=1;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=100, random_state=None;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=0;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=1;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.190 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.25, n_estimators=125, random_state=None;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.320 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=0;, score=0.455 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.320 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=1;, score=0.455 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.250 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.320 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=25, random_state=None;, score=0.455 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=0;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=1;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.250 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.222 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=50, random_state=None;, score=0.111 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=0;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.154 total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=1;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.190 total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.261 total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.154 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=75, random_state=None;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=0;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=1;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=100, random_state=None;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=0;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=1;, score=0.211 total time=   0.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.273 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.333 total time=   0.1s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.160 total time=   0.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=1.5, n_estimators=125, random_state=None;, score=0.211 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostClassifier(),\n",
       "             param_grid={'algorithm': ['SAMME', 'SAMME.R'],\n",
       "                         'learning_rate': [1.0, 0.1, 0.3, 0.5, 0.75, 1.25, 1.5],\n",
       "                         'n_estimators': [25, 50, 75, 100, 125],\n",
       "                         'random_state': [0, 1, None]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchADB.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "964950dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME.R', 'learning_rate': 1.5, 'n_estimators': 25, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "print(searchADB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99373a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADBClassifier_opti = AdaBoostClassifier(algorithm = 'SAMME.R', learning_rate = 1.5, n_estimators = 25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2bf72fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=1.5, n_estimators=25, random_state=0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADBClassifier_opti.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "15f155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_opti_pred_ADB = ADBClassifier_opti.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a95e7929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9298892988929889\n",
      "Precision:  0.9298892988929889\n",
      "Recall:  0.34782608695652173\n",
      "F1Score:  0.4571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_opti_pred_ADB))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_opti_pred_ADB))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_opti_pred_ADB))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_opti_pred_ADB))\n",
    "\n",
    "#Adaboost end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ee1a118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost start\n",
    "from xgboost import XGBClassifier\n",
    "xgbClassifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "028f628a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbClassifier.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "45e9ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XG = xgbClassifier.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1df0cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.922509225092251\n",
      "Precision:  0.922509225092251\n",
      "Recall:  0.30434782608695654\n",
      "F1Score:  0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_pred_XG))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_pred_XG))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_pred_XG))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_pred_XG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9cadc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_XGB = {\n",
    "    'base_score' : [0.1, 0.3, 0.5, 0.7],\n",
    "    'booster' : ['gbtree', 'gblinear', 'dart'],\n",
    "    'learning_rate':[0.1, 0.3, 0.5],\n",
    "    'subsample' : [0.5,1.0, 1.2],\n",
    "    'n_estimators': [100, 400,700],\n",
    "    'max_depth' : [3,6,9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "45909eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchXG = GridSearchCV(xgbClassifier, param_grid_XGB, scoring='f1', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1441898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.3s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.3s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.4s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.3s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.3s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.3s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.3s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.3s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.571 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:02:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.1, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.7s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.500 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.8s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.4s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.571 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.5s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.6s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.5s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.4s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.6s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.6s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.6s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.5s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.5s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.6s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.7s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.6s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.6s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.8s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.286 total time=   3.1s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.6s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.5s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.8s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.6s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.6s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.8s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.8s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.8s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   8.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.9s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time= 5.7min\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.3s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.5s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.4s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.6s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.7s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.286 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.7s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.7s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   6.8s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.8s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.8s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   6.8s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.1s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.1, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.500 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.4s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.4s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[14:23:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:23:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.3, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.500 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.1s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.1s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.6s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.4s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.5s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.8s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.6s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.5s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time= 6.5min\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   3.6s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.7s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.8s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.7s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.286 total time=   6.8s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   6.7s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.8s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.8s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.1s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.286 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.1s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.4s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.6s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.1s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.2s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.3, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.500 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:44:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.8s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.9s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.7s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.9s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.500 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.6s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.3s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.6s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.286 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.7s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.6s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.6s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.6s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.6s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.5s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.8s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.7s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time= 6.5min\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.500 total time=   7.1s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.7s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   6.5s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.7s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.7s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.8s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.3s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.1s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.286 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.444 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.5, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.444 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.250 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.286 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=gbtree, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[15:06:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.1s\n",
      "[15:06:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   0.0s\n",
      "[15:06:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 2/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 3/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[15:06:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.1s\n",
      "[15:06:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bylevel\", \"colsample_bynode\", \"colsample_bytree\", \"gamma\", \"grow_policy\", \"interaction_constraints\", \"max_bin\", \"max_cat_to_onehot\", \"max_delta_step\", \"max_depth\", \"max_leaves\", \"min_child_weight\", \"monotone_constraints\", \"num_parallel_tree\", \"predictor\", \"sampling_method\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[CV 5/5] END base_score=0.7, booster=gblinear, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.444 total time=   0.1s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.500 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.444 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.7s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   5.5s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.444 total time=   7.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.6s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.400 total time=   2.5s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.444 total time=   7.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.400 total time=   7.4s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.4s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.1, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.6s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.5s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=17.4min\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.250 total time=  13.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=  12.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=12.8min\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.333 total time=  15.6s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=  14.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=  13.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=  11.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.1s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.6s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.6s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.250 total time=   6.7s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.1s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.5s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.250 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.3, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   7.1s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.444 total time=   6.8s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.8s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=3, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.400 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.4s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.7s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.286 total time=   7.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.444 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=0.5;, score=0.333 total time=   7.1s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.333 total time=   7.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=6, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.000 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.444 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=0.5;, score=0.333 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.333 total time=   0.2s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.000 total time=   0.2s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.0;, score=0.286 total time=   0.2s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=100, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.400 total time=   2.3s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.250 total time=   2.4s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=0.5;, score=0.333 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.333 total time=   2.4s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.4s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.000 total time=   2.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.0;, score=0.286 total time=   2.3s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=400, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.8s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.286 total time=   6.8s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.000 total time=   6.9s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.444 total time=   6.9s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=0.5;, score=0.333 total time=   6.8s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   6.9s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.333 total time=   6.9s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.2s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.000 total time=   7.3s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.0;, score=0.286 total time=   6.9s\n",
      "[CV 1/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END base_score=0.7, booster=dart, learning_rate=0.5, max_depth=9, n_estimators=700, subsample=1.2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "1080 fits failed out of a total of 4860.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1080 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/xgboost/core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/xgboost/core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/xgboost/core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/xgboost/core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.06666667 0.3752381         nan 0.13333333 0.2               nan\n",
      " 0.2        0.13333333        nan 0.06666667 0.32761905        nan\n",
      " 0.13333333 0.21333333        nan 0.2        0.21333333        nan\n",
      " 0.06666667 0.32761905        nan 0.13333333 0.21333333        nan\n",
      " 0.2        0.21333333        nan 0.06666667 0.2               nan\n",
      " 0.24761905 0.13333333        nan 0.2        0.13333333        nan\n",
      " 0.06666667 0.21333333        nan 0.19047619 0.21333333        nan\n",
      " 0.2        0.21333333        nan 0.06666667 0.21333333        nan\n",
      " 0.19047619 0.21333333        nan 0.2        0.21333333        nan\n",
      " 0.2        0.2               nan 0.2        0.13333333        nan\n",
      " 0.18333333 0.13333333        nan 0.2        0.21333333        nan\n",
      " 0.19047619 0.21333333        nan 0.13333333 0.21333333        nan\n",
      " 0.2        0.21333333        nan 0.19047619 0.21333333        nan\n",
      " 0.13333333 0.21333333        nan 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.3752381         nan 0.12380952 0.2               nan\n",
      " 0.23333333 0.13333333        nan 0.         0.32761905        nan\n",
      " 0.13333333 0.21333333        nan 0.23333333 0.21333333        nan\n",
      " 0.         0.32761905        nan 0.13333333 0.21333333        nan\n",
      " 0.23333333 0.21333333        nan 0.13333333 0.2               nan\n",
      " 0.19047619 0.13333333        nan 0.19047619 0.13333333        nan\n",
      " 0.13333333 0.21333333        nan 0.19047619 0.21333333        nan\n",
      " 0.19047619 0.21333333        nan 0.13333333 0.21333333        nan\n",
      " 0.19047619 0.21333333        nan 0.19047619 0.21333333        nan\n",
      " 0.12380952 0.2               nan 0.23333333 0.13333333        nan\n",
      " 0.19047619 0.13333333        nan 0.13333333 0.21333333        nan\n",
      " 0.23333333 0.21333333        nan 0.2        0.21333333        nan\n",
      " 0.13333333 0.21333333        nan 0.23333333 0.21333333        nan\n",
      " 0.2        0.21333333        nan 0.13333333 0.34666667        nan\n",
      " 0.2        0.22380952        nan 0.2        0.18095238        nan\n",
      " 0.13333333 0.30380952        nan 0.2        0.20380952        nan\n",
      " 0.2        0.12380952        nan 0.13333333 0.30380952        nan\n",
      " 0.2        0.20380952        nan 0.2        0.12380952        nan\n",
      " 0.2        0.22380952        nan 0.2        0.12380952        nan\n",
      " 0.2        0.12380952        nan 0.2        0.20380952        nan\n",
      " 0.2        0.12380952        nan 0.2        0.12380952        nan\n",
      " 0.2        0.20380952        nan 0.2        0.12380952        nan\n",
      " 0.13333333 0.12380952        nan 0.13333333 0.18095238        nan\n",
      " 0.2        0.12380952        nan 0.13333333 0.12380952        nan\n",
      " 0.19047619 0.20380952        nan 0.19047619 0.12380952        nan\n",
      " 0.13333333 0.12380952        nan 0.19047619 0.12380952        nan\n",
      " 0.19047619 0.12380952        nan 0.13333333 0.12380952        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.13333333 0.34666667        nan\n",
      " 0.19047619 0.22380952        nan 0.23333333 0.18095238        nan\n",
      " 0.2        0.30380952        nan 0.19047619 0.20380952        nan\n",
      " 0.23333333 0.12380952        nan 0.2        0.30380952        nan\n",
      " 0.19047619 0.20380952        nan 0.23333333 0.12380952        nan\n",
      " 0.19047619 0.22380952        nan 0.2        0.12380952        nan\n",
      " 0.19047619 0.12380952        nan 0.19047619 0.20380952        nan\n",
      " 0.2        0.12380952        nan 0.19047619 0.12380952        nan\n",
      " 0.19047619 0.20380952        nan 0.2        0.12380952        nan\n",
      " 0.19047619 0.12380952        nan 0.23333333 0.18095238        nan\n",
      " 0.23333333 0.12380952        nan 0.23333333 0.12380952        nan\n",
      " 0.19047619 0.20380952        nan 0.23333333 0.12380952        nan\n",
      " 0.19047619 0.12380952        nan 0.19047619 0.12380952        nan\n",
      " 0.23333333 0.12380952        nan 0.19047619 0.12380952        nan\n",
      " 0.13333333 0.34666667        nan 0.2        0.22380952        nan\n",
      " 0.2        0.18095238        nan 0.13333333 0.30380952        nan\n",
      " 0.2        0.20380952        nan 0.2        0.20380952        nan\n",
      " 0.13333333 0.30380952        nan 0.2        0.20380952        nan\n",
      " 0.2        0.12380952        nan 0.2        0.22380952        nan\n",
      " 0.2        0.12380952        nan 0.2        0.12380952        nan\n",
      " 0.13333333 0.26095238        nan 0.13333333 0.12380952        nan\n",
      " 0.13333333 0.12380952        nan 0.13333333 0.20380952        nan\n",
      " 0.13333333 0.12380952        nan 0.13333333 0.12380952        nan\n",
      " 0.2        0.26095238        nan 0.19047619 0.12380952        nan\n",
      " 0.2        0.12380952        nan 0.19047619 0.20380952        nan\n",
      " 0.2        0.12380952        nan 0.13333333 0.12380952        nan\n",
      " 0.19047619 0.12380952        nan 0.2        0.12380952        nan\n",
      " 0.13333333 0.12380952        nan 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.19047619 0.34666667        nan 0.23333333 0.22380952        nan\n",
      " 0.23333333 0.18095238        nan 0.19047619 0.30380952        nan\n",
      " 0.19047619 0.20380952        nan 0.23333333 0.20380952        nan\n",
      " 0.19047619 0.30380952        nan 0.19047619 0.20380952        nan\n",
      " 0.23333333 0.12380952        nan 0.19047619 0.22380952        nan\n",
      " 0.19047619 0.12380952        nan 0.19047619 0.12380952        nan\n",
      " 0.23333333 0.26095238        nan 0.2        0.12380952        nan\n",
      " 0.19047619 0.12380952        nan 0.23333333 0.20380952        nan\n",
      " 0.2        0.12380952        nan 0.19047619 0.12380952        nan\n",
      " 0.19047619 0.26095238        nan 0.23333333 0.12380952        nan\n",
      " 0.23333333 0.12380952        nan 0.23333333 0.20380952        nan\n",
      " 0.23333333 0.12380952        nan 0.18095238 0.12380952        nan\n",
      " 0.19047619 0.12380952        nan 0.23333333 0.12380952        nan\n",
      " 0.21269841 0.12380952        nan 0.13333333 0.33555556        nan\n",
      " 0.2        0.18095238        nan 0.2        0.18095238        nan\n",
      " 0.13333333 0.30380952        nan 0.2        0.20380952        nan\n",
      " 0.19047619 0.20380952        nan 0.13333333 0.30380952        nan\n",
      " 0.2        0.20380952        nan 0.19047619 0.20380952        nan\n",
      " 0.2        0.22380952        nan 0.2        0.12380952        nan\n",
      " 0.2        0.12380952        nan 0.2        0.26095238        nan\n",
      " 0.2        0.12380952        nan 0.2        0.12380952        nan\n",
      " 0.2        0.20380952        nan 0.2        0.12380952        nan\n",
      " 0.2        0.12380952        nan 0.19047619 0.18095238        nan\n",
      " 0.18333333 0.12380952        nan 0.13333333 0.11428571        nan\n",
      " 0.18333333 0.20380952        nan 0.19047619 0.12380952        nan\n",
      " 0.11666667 0.12380952        nan 0.18333333 0.20380952        nan\n",
      " 0.19047619 0.12380952        nan 0.11666667 0.12380952        nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.23333333 0.33555556        nan\n",
      " 0.23333333 0.18095238        nan 0.22222222 0.18095238        nan\n",
      " 0.22222222 0.30380952        nan 0.18333333 0.20380952        nan\n",
      " 0.22222222 0.20380952        nan 0.23333333 0.30380952        nan\n",
      " 0.18333333 0.20380952        nan 0.22222222 0.20380952        nan\n",
      " 0.22222222 0.22380952        nan 0.18333333 0.12380952        nan\n",
      " 0.18333333 0.12380952        nan 0.22222222 0.26095238        nan\n",
      " 0.18333333 0.12380952        nan 0.18333333 0.12380952        nan\n",
      " 0.22222222 0.20380952        nan 0.18333333 0.12380952        nan\n",
      " 0.18333333 0.12380952        nan 0.22222222 0.18095238        nan\n",
      " 0.18333333 0.12380952        nan 0.22222222 0.11428571        nan\n",
      " 0.22222222 0.20380952        nan 0.19666667 0.12380952        nan\n",
      " 0.21269841 0.12380952        nan 0.22222222 0.20380952        nan\n",
      " 0.19666667 0.12380952        nan 0.21269841 0.12380952        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     callbacks=None, colsample_bylevel=1,\n",
       "                                     colsample_bynode=1, colsample_bytree=1,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=0, gpu_id=-1,\n",
       "                                     grow_policy='depthwise',\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.300000012, max_bin=256,\n",
       "                                     max_cat_to_...\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints='()',\n",
       "                                     n_estimators=100, n_jobs=0,\n",
       "                                     num_parallel_tree=1, predictor='auto',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1, ...),\n",
       "             param_grid={'base_score': [0.1, 0.3, 0.5, 0.7],\n",
       "                         'booster': ['gbtree', 'gblinear', 'dart'],\n",
       "                         'learning_rate': [0.1, 0.3, 0.5],\n",
       "                         'max_depth': [3, 6, 9],\n",
       "                         'n_estimators': [100, 400, 700],\n",
       "                         'subsample': [0.5, 1.0, 1.2]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchXG.fit(x_test_array, y_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f5b2c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.1, 'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(searchXG.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c523d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbClassifier_opti = XGBClassifier(base_score=0.1, booster='gbtree', learning_rate = 0.1, max_depth = 3, n_estimators = 100, subsample = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "12d2565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.1, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbClassifier_opti.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "046c4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_opti_pred_XG = xgbClassifier_opti.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "738c57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.933579335793358\n",
      "Precision:  0.933579335793358\n",
      "Recall:  0.30434782608695654\n",
      "F1Score:  0.43750000000000006\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_array, y_opti_pred_XG))\n",
    "print(\"Precision: \", metrics.accuracy_score(y_test_array, y_opti_pred_XG))\n",
    "print(\"Recall: \", metrics.recall_score(y_test_array, y_opti_pred_XG))\n",
    "print(\"F1Score: \", metrics.f1_score(y_test_array, y_opti_pred_XG))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
